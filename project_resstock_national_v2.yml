schema_version: '0.3'
buildstock_directory: ../resstock  # Relative to this file or absolute
project_directory: project_national  # Relative to buildstock_directory
output_directory: outputs
weather_files_url: https://data.nrel.gov/system/files/156/BuildStock_TMY3_FIPS.zip
#weather_files_path: /shared-projects/buildstock/weather/BuildStock_TMY3_FIPS.zip  # Relative to this file or absolute path to zipped weather files

sampler:
  type: residential_quota_downselect
  args:
    n_datapoints: 200
    logic:
      - Geometry Building Type RECS|Single-Family Detached
      - Vacancy Status|Occupied
    resample: false

workflow_generator:
  type: residential_default
  args:
    timeseries_csv_export:
      reporting_frequency: Hourly
      include_enduse_subcategories: true

baseline:
  n_buildings_represented: 133172057  # Total number of residential dwelling units in contiguous United States, including unoccupied units, resulting from a census tract level query of ACS 5-yr 2016 (i.e. 2012-2016), using this script: https://github.com/NREL/resstock-estimation/blob/master/sources/spatial/tsv_maker.py.

upgrades:
  - upgrade_name: Triple-Pane Windows
    options:
      - option: Windows|Triple, Low-E, Non-metal, Air, L-Gain
#        apply_logic:
        costs:
          - value: 45.77
            multiplier: Window Area (ft^2)
        lifetime: 30

aws:
  # The job_identifier should be unique, start with alpha, not include dashes, and limited to 10 chars or data loss can occur
  job_identifier: utwebber4
  s3:
    bucket: 986162565119-resbldg-datasets
    prefix: testing4
  region: us-east-1
  use_spot: false
  batch_array_size: 10
  # To receive email updates on job progress accept the request to receive emails that will be sent from Amazon
  notifications_email: alex@austin.utexas.edu

postprocessing:
  aws:
    region_name: us-east-1
    s3:
      bucket: 986162565119-resbldg-datasets
      prefix: testing_postprocessing4
    athena:
      glue_service_role: service-role/AWSGlueServiceRole-default
      database_name: testing4
      max_crawling_time: 300 # time to wait for the crawler to complete before aborting it
